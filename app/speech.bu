import os
import time
from utils import multi_ext_glob, ext_conversion
from whisper_stt import WhisperSTT
from annote import Annotation
# from whisper_api import InferenceRequest

class Speech:
    def __init__(
        self,
        # input_dir: str = ".", # MOVE
        # save_dir: str = "/app/data", # MOVE

        # video_ext_list: list = ["mp4"],
        # audio_ext_list: list = ["mp4", "wav", "m4a"],

        axis: int = -1,
        n_mels: int = 128,
        length: int = 480000,
        model: str = "large",
        language: str = None,

        pipeline_model: str = "pyannote/speaker-diarization-3.1",
        use_auth_token: str = "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"        
        ):
        print("[+] INITIALIZING MAIN")
        start = time.time()

        self.input_dir = input_dir
        self.save_dir = save_dir

        self.video_ext_list = video_ext_list
        self.audio_ext_list = audio_ext_list

        self.audio_list = []

        self.axis = axis
        self.n_mels = n_mels
        self.length = length
        self.model = model
        self.language = language
        
        self.pipeline_model = pipeline_model
        self.use_auth_token = use_auth_token

        print("[-] INITIALIZATION COMPLETE.\n\tTIME TAKEN:", time.time() - start)


    def convert_to_wav(self, target_file: str):
        print("[+] CONVERTING TO WAV")
        start = time.time()

        target_file_name, target_file_ext = os.path.splitext(target_file)
        if target_file_ext == "wav": return

        converted_file = target_file.replace(target_file_ext, "wav")
        ext_conversion(
            target_file, 
            os.path.join(self.save_dir, f"{target_file_name}.wav")
            )
        print("[-] CONVERSION COMPLETE.\n\tTIME TAKEN:", time.time() - start)

    
    def get_video_list(self):
        self.video_list = multi_ext_glob(self.input_dir, self.video_ext_list, recursive=True)
        print(f"[*]\tVIDEO EXTENSIONS: {self.video_ext_list}\n\tLENGTH OF VIDEOS: {len(self.video_list)}")
    

    def get_audio_list(self):
        self.audio_list = multi_ext_glob(self.input_dir, self.audio_ext_list, recursive=True)
        print(f"[*]\tAUDIO EXTENSIONS: {self.audio_ext_list}\n\tLENGTH OF AUDIOS: {len(self.audio_list)}")


    def get_wav_list(self):
        self.wav_list = multi_ext_glob(self.input_dir, ["wav"], recursive=True)
        print(f"[*]\tAUDIO EXTENSIONS: {['wav']}\n\tLENGTH OF AUDIOS: {len(self.audio_list)}")

    
    def start_apps(self):
        self.whisper_stt = WhisperSTT(
            audio_list = self.wav_list,
            save_dir = self.save_dir,
            axis = self.axis,
            n_mels = self.n_mels,
            length = self.length,
            model = self.model,
            language = self.language
        )

        # self.annotation = Annotation(
        #     audio_list = self.wav_list,
        #     save_dir = self.save_dir,

        #     pipeline_model = self.pipeline_model,
        #     use_auth_token = self.use_auth_token
        # )


    def run(self):
        self.start_apps()

        whisper_result = self.whisper_stt.run()

        for result in whisper_result:
            for data in result:
                print(f"{data}: {result[data]}")

        # annotation_result = self.annotation.run()

        # for result in annotation_result:
        #     print(result)


        return whisper_result

if __name__ == "__main__":
    input_dir = "/app/data/240611"
    save_dir  = "/app/data/240611/result"


    test = MainProcess(
        input_dir=input_dir,
        save_dir=save_dir,
        language="ko"
        )

    test.get_video_list()
    for video in test.video_list:
        test.convert_to_wav(video)

    test.get_audio_list()
    for audio in test.audio_list:
        test.convert_to_wav(audio)

    test.get_wav_list()

    test.run()
